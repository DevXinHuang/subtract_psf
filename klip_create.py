#!/usr/bin/env python
import mkl
import multiprocessing as mp
import numpy as np
import os
import pickle
import poppy
import time
import webbpsf

from astropy.io import fits
from functools import partial
from multiprocessing import Pool

class KlipCreate():
    '''
    Create directories with "observations" of reference and target data cubes
    generated by WebbPSF's JWST NIRSpec IFU mode.

    In an indvidual directory, there is one data cube per dither position for
    both the reference and target image sets, plus an additional data cube for
    each centered on (0, 0) (before accounting for pointing error). Each set
    must have the same number of images.

    Directories also include `attr.pkl`, afile with instrument information saved from this class' attributes (dither positions, errors, etc.), and
    `original_call.pkl`, which contains the terminal call used to create this
    class if you did so through `make_img_dir.py`.

    This class uses parallelization to create all directories simultaneously.
    Randomization from overall/dither pointing errors leads to differences
    between corresponding images in different directories, just as you'd have
    in different "real" observations of the same point in the sky.

    Once the process is finished, use KlipRetrieve() to perform PSF subtraction
    and analyze the results.

    Arguments:
    ----------
    new_dir : str, required
        The base name for the set of directories. (e.g. base0, base1, etc.)

    num_dir : int, required
        The number of directories to create. Must be 16 or fewer. (default: 1)

    dithers : an N-by-2 array of floats, optional
        An array with positions indicating offsets for a proposed dither cycle.
        Each entry is a length-2 array with an x and y position; the number of
        entries in the outer array is up to the user. (default: None, which
        triggers the first 9 steps of JWST's small-pattern dither cycle)

    pointing_error : bool, optional
        Whether to include a randomly drawn offset in each set of images
        resulting from JWST's overall pointing uncertainty of .25 arcseconds.
        (default: True)

    oversample : int
        The factor beyond the detector's pixel count by which to sample the
        scene in ext=0 of the data cubes. Has a large effect on file creation
        speeds. For quick tests, the recommended setting here is 1. (default: 4)

    temp_slices : int
        The number of wavelength slices to include in each data cube. Also has
        a large effect on file creation speeds; try 3 or 6 slices for quick
        tests. (default: None, which triggers a calculation based on
        wavelength range and resolving power. For the NIRSpec IFU, it's 1530.)
    '''

    def __init__(self, new_dir, num_dir=1,
                 dithers=None, pointing_error=True,
                 oversample=4, temp_slices=None):
        # cap number to make simultaneously at number of CPU cores in science5
        if num_dir > 16:
            raise ValueError('num_dir must be fewer than or equal to 16')

        # set number of pixels to put in field of view for calc_psf
        self.fov_pixels = 30

        # wavelength range and resolution considered for PSFs in microns
        # (taken from grating/disperser 395H and filter 290LP)
        # CHANGE TO INCORPORATE ASTROPY UNITS, MAKE CORRESPONDING CHANGE IN _count_photons IN klip_retrieve.py
        self.lo_wv = 2.87e-6
        self.hi_wv = 5.14e-6
        self.resolve_pwr = 2700

        # get array of target wavelengths
        # (array length is an approximation of (∂λ / λ)
        #  because we use the mean of wvnth range for ∂λ instead of integrating)
        slice_width = np.mean([self.lo_wv, self.hi_wv]) / self.resolve_pwr
        slices = int((self.hi_wv - self.lo_wv) / slice_width)
        if temp_slices:
            slices = temp_slices # orig. 6; IDEALLY REMOVE THIS LINE
        # T0-D0: ELIMINATE 100 WAVELENGTH LIMIT IN CALC_DATA* IN WEBBPSF!
        self.wvlnths = np.linspace(self.lo_wv, self.hi_wv,
                                   num=slices, endpoint=True)

        # NOTE: at a resolving power of 2700, the PSFs of step X and step X+1
        # are basically the same. as such, if you see large changes from step
        # to step, it's probably a companion and not due to the instrument
        # since speckle does not change with wavelength

        # positions of small dither cycle relative to star at (0, 0)
        if dithers is not None:
            self.dithers = dithers
        else:
            dither_x = np.array([-.175, .175, .025, -.025,
                                 .05, -.1, .05, .1, -.1])
            dither_y = np.array([-.125, .125, -.175, .175,
                                 -.05, .0, .1, .05, -.20001])
            self.dithers = np.array(list(zip(dither_x, dither_y)))

        # insert (0, 0) to also get PSF with star at center ** (my edit) **
        self.positions = np.insert(self.dithers, 0, [0, 0], axis=0)
        #self.positions = dithers # the actual cycle

        # parallelize processes so we can generate all directories concurrently
        mkl.set_num_threads(1) # prevent numpy from multithreading
        # (this enables true parallelization, limiting each CPU's usage to 100%)
        # (requires numpy usage of MKL; OPENBLAS/NUMEXPR/etc require other
        # commands. check np.__config__.show() to confirm)
        pool = Pool(num_dir) # initialize `num_dir` processes
        multithread = pool.map(partial(self._create_data_cubes,
                                       pnt_err=pointing_error,
                                       oversample=oversample),
                               [new_dir + str(i) for i in range(num_dir)])

        # OLD: generate uncertainties for reference and science cases,
        # add them to the default positions,
        # then use these values to create a data cube for each image
        #for i in range(num_dir):
        #    self._create_data_cubes(new_dir + str(i))
            #print('***********************\n'
            #      + f"through {i + 1} of {num_dir} directories"
            #      + '\n***********************')

        # good practice once the parallelized portion is complete
        pool.close()
        pool.join()

    def _randomize_errors(self, pnt_err):
        '''
        Randomize the pointing and dither errors so you can use the same class
        instance to generate multiple directories' worth of image test cases.
        '''
        np.random.seed()
        # generate uncertainties in pointing the detector and the dither cycle
        if pnt_err:
            self.point_err_ax = np.random.normal(0, .25, 4)
        else:
            self.point_err_ax = np.zeros(4)
        self.dith_err_ax = np.random.normal(0, .004, (2,len(self.positions),2))
        # shape is 2 cases (ref/sci), # of positions, 2 axes (x/y)

        # separate the randomized positions into reference and science sets
        self.draws_ref = (self.positions
                          + self.point_err_ax[:2] + self.dith_err_ax[0])
        self.draws_sci = (self.positions
                          + self.point_err_ax[2:] + self.dith_err_ax[1])

    def _create_data_cubes(self, new_dir, pnt_err, oversample):
        # PRINT ATTRIBUTES SO YOU CAN CHECK

        # check if specified directory already exists
        if os.path.isdir(new_dir):
            raise ValueError('there already exists a directory with that name')
        else:
            os.mkdir(new_dir)

        # generate uncertainties for reference and science cases
        self._randomize_errors(pnt_err)

        # save this instance's class attributes
        with open(new_dir + '/attr.pkl', 'wb') as file:
            pickle.dump(vars(self), file)

        # create a set of images for the reference and science cases
        positions_twice = np.tile(self.positions, (2, 1))
        start = time.time()

        for i, pos in enumerate(positions_twice):

            # set up new instance of NIRSpec class with proper filter/mask
            ns = webbpsf.NIRSpec()
            ns.filter = 'F110W'
            ns.image_mask = 'IFU'

            # apply offset due to uncertainty in overall pointing from
            if i < len(self.positions):
                x_off = pos[0] + self.point_err_ax[0]
                y_off = pos[1] + self.point_err_ax[1]
            else:
                x_off = pos[0] + self.point_err_ax[2]
                y_off = pos[1] + self.point_err_ax[3]

            # apply dither-specific offset for small, 9-point cycle pointings
            # i personally add the (0, 0) point to bring the total to 10,
            # so i'll have 2 x 10 data cubes
            if i > 0 and i < len(self.positions):
                x_off += self.dith_err_ax[0][i][0]
                y_off += self.dith_err_ax[0][i][1]
                #x_off += dith_err_ax[0][0][0] # apply same dither error to each step,
                #y_off += dith_err_ax[0][0][1] # like before (for testing purposes)

            elif i > len(self.positions):
                x_off += self.dith_err_ax[1][i - len(self.positions)][0]
                y_off += self.dith_err_ax[1][i - len(self.positions)][1]
                #x_off += dith_err_ax[1][0][0] # apply same dither error to each step,
                #y_off += dith_err_ax[1][0][1] # like before (for testing purposes)


            # create data cube
            ns.options['source_offset_x'] = x_off
            ns.options['source_offset_y'] = y_off

            cube = ns.calc_datacube(oversample=oversample,
                                    fov_pixels=self.fov_pixels,
                                    wavelengths=self.wvlnths,
                                    add_distortion=False) # removes ext 2 & 3

            # check whether this is a reference or science image (refs come first)
            is_ref = i < len(self.positions)

            cube.writeto(new_dir
                         + ('/ref_image' if is_ref else '/sci_image')
                         + (str(i) if is_ref else str(i - len(self.positions)))
                         + '.fits')

            print(f"{len(self.positions) - 1 - i % len(self.positions)} to go in "
                  f"{'reference' if i < len(self.positions) else 'science'}"
                  f", {time.time() - start:.3f} sec",
                  flush=True)

            #if i > 1:
                #break
